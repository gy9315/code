# machine_learning

## 2024-03-05

### 학습내용
- 머신러닝 학습을 위한 실험 설계와 코드 실행 환경 기획
- 데이터 분류 및 예측 문제를 구분하고 실험 단위를 구조화함
- 다양한 예제 데이터를 통해 전체 학습 방향을 정립함

### 개인 복습/실습
- 학습 초반부로 전체 실습 흐름을 구상하고 실험 단위를 나누는 작업을 진행함
- 어떤 문제를 예측 문제로 보고, 분류 문제로 볼지에 대한 기준을 스스로 세우며 다양한 예제를 탐색함
- 전체 학습 계획을 수립하며 어떤 방식으로 실습을 이어갈지 고민함

### 회고
- 처음 머신러닝 실습 구조를 접하면서 전체적인 윤곽을 잡고, 향후 실습이 어떤 방향으로 나아갈지를 설계할 수 있었다.

## 2024-03-06

### 학습내용
- 단순 선형 회귀부터 다항 회귀(polyfit)까지의 예측 모델 학습
- 평균, 편차, 분산, 결정계수(R2)의 개념과 계산 방식을 적용
- 예측 모델의 적합도를 시각화하고 분석함

### 개인 복습/실습
- 회귀 모델을 구성하며 numpy 기반으로 평균, 분산, R2 등 통계 지표를 직접 계산해봄
- polyfit으로 다항 회귀 모델을 구성할 때 차수 변화에 따라 과적합 위험이 어떻게 나타나는지 시각적으로 비교
- 'polyfit은 과적합이 생기지 않나?'라는 질문을 통해 모델 복잡도와 예측 정확도의 trade-off를 이해하려 노력함
- 결정계수 R2의 해석 방법이 직관적으로 와닿지 않아 여러 방식으로 값을 확인하고 이해함

### 회고
- 선형 회귀라는 간단한 모델에서부터도 예측 정확도와 모델 해석의 균형을 고려해야 함을 배웠고,
  단순히 수식이 아닌 그래프와 해석이 병행돼야 한다는 점을 느꼈다.

## 2024-03-07

### 학습내용
- KNN 회귀모델을 학습하고, k값의 변화에 따라 오버피팅과 언더피팅이 어떻게 달라지는지 실습을 통해 체감
- 거리 기반 모델의 예측 방식과 모델 민감도를 확인함

### 개인 복습/실습
- KNN 회귀모델을 직접 구현하며 k값을 조정했을 때 예측이 얼마나 유연해지는지 확인함
- 거리 계산 방식을 활용한 모델이기에, feature scaling이 결과에 미치는 영향도 함께 비교함
- 'KNN에서 k가 커지면 정확도가 왜 떨어질 수 있어?'라는 의문을 해결하며 과적합-과소적합 개념을 구체화함
- KFold 교차검증을 통해 k 선택이 단순 성능 수치가 아니라 일반화 측면에서의 영향을 주는 점을 실감함

### 회고
- KNN은 단순한 알고리즘이지만, 거리와 k값이라는 두 가지 요소에 의해 예측 결과가 민감하게 변하는 것을 확인하며,
  모델 해석력의 중요성을 배웠다.

## 2024-03-10

### 학습내용
- 정규화 회귀 기법(Lasso, Ridge, ElasticNet)을 비교하며,
  L1, L2 패널티의 개념과 회귀계수에 미치는 영향을 학습함
- 불필요한 변수를 제거하는 효과를 수치적으로 비교하며 해석 중심으로 학습함

### 개인 복습/실습
- 정규화 기법에서 L1, L2가 손실함수에 어떤 영향을 주는지 수식과 시각화를 통해 학습함
- 각 모델에 따라 회귀계수의 크기와 생략 여부가 달라지는 점을 비교하며 해석력을 키움
- Lasso와 Ridge의 차이를 정리하며 정규화 방식의 핵심을 분리해서 이해함
- ElasticNet이 두 방식을 어떻게 절충하는지를 수치 실험과 시각화로 확인함

### 회고
- 과적합을 해결하는 도구로써 정규화 기법을 단순 적용하는 데 그치지 않고,
  각 패널티가 예측 모델의 해석 가능성과 어떻게 연결되는지를 고민할 수 있게 되었다.

## 2024-03-11

### 학습내용
- auto_mpg와 housing 데이터를 활용해 회귀 모델의 실제 적용 사례를 학습함
- 단순 선형 회귀와 다항 회귀를 비교하고, 여러 지표로 모델 성능을 해석하는 연습을 진행함

### 개인 복습/실습
- 회귀모델을 다양한 실제 데이터셋에 적용하며, 과적합과 일반화 성능을 비교함
- 손실 함수로 MSE와 CrossEntropy의 차이를 학습하며 상황별 적용 방식을 이해함
- 시각화와 성능지표(R2, RMSE 등)를 동시에 고려하면서 단순 점수 이상의 해석 방법을 고민함
- 다항회귀에서 모델 차수를 바꾸며 오차율이 어떻게 변화하는지 반복 실험을 통해 파악함

### 회고
- 실제 데이터를 통한 모델 해석이 단순 수치 비교보다 더 많은 통찰을 제공한다는 점을 경험하며,
  데이터의 구조와 예측 모델의 해석력을 연결짓는 능력이 향상되었다.

## 2024-03-12

### 학습내용
- 경사하강법의 원리를 수학적으로 정리하고,
  수치 미분 및 행렬곱을 통해 손실함수의 기울기를 계산하는 실습을 수행함
- 학습률의 차이가 오차 수렴에 미치는 영향을 시각적으로 비교함

### 개인 복습/실습
- 편미분을 직접 전개하고 numpy로 수치미분을 구현하며 수학적 개념을 실제 코드로 연결함
- MSE를 줄이기 위한 경사하강법 수식을 유도하며 수식과 구현의 연계성을 강화함
- 학습률 변화가 오차 수렴에 어떤 영향을 주는지 그래프를 반복 확인하며 최적화 직관을 키움
- 행렬곱(dot product)의 개념을 반복 정리하며 모델 예측의 수학적 기반을 이해함

### 회고
- 머리로만 알고 있던 미분과 기울기, 손실함수가 실제 코드로 구현될 수 있다는 사실이
  학습을 매우 입체적으로 만들어주었고, 수치와 수식의 해석력 모두 향상되었다.

## 2024-03-13

### 학습내용
- 데이터 전처리 기법으로 정규화(MinMaxScaler, StandardScaler)를 비교하고,
  로지스틱 회귀 모델의 수식 기반 이해와 적용을 중심으로 실습함

### 개인 복습/실습
- 정규화 방식에 따라 데이터 분포와 모델 성능이 어떻게 달라지는지 시각적으로 비교함
- 정규화 방식의 차이를 학습하며 평균 기반 vs 범위 기반 정규화의 개념을 정리함
- 로지스틱 회귀의 수식을 직접 구현하며 sigmoid 함수와 확률 기반 분류의 차이를 학습함
- 분류모델이 단순 회귀와 다르게 해석되는 지점을 비교 분석하며 개념 전환을 훈련함

### 회고
- 데이터 전처리 방식이 단순 보조 도구가 아니라,
  전체 모델의 성능과 구조 해석에 직접적 영향을 준다는 사실을 체감하며 실무적인 감각을 키웠다.

## 2024-03-14

### 학습내용
- 전체 회귀 모델을 통합 비교하며,
  모델 선택의 기준을 정확도뿐 아니라 해석력, 일반화 가능성까지 고려하는 방식으로 확장함
- 실험 결과를 정리하고 발표 자료 형태로 구성함

### 개인 복습/실습
- 지금까지 학습한 선형회귀, 다항회귀, KNN, 정규화 모델을 통합 비교함
- 성능지표(R2, RMSE, 시각화)를 기준으로 모델을 선택하는 기준을 정리함
- 성능이 좋아도 복잡한 모델이 항상 좋은가?라는 고민을 통해 모델 해석력에 대해 다시 정리함
- 발표용 문서에 모든 실험 결과를 정리하며 흐름을 한눈에 파악할 수 있는 구성을 학습함

### 회고
- 단순히 실습을 따라가는 수준에서 벗어나,
  각 모델의 장단점과 선택 기준을 종합적으로 고민할 수 있었던 시점으로,
  ML 학습의 전반적인 흐름을 마무리하며 성찰할 수 있었다.
