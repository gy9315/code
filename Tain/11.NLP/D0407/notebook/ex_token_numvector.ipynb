{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ 자연어 전처리 - 정제+토큰화 ]\n",
    "- 정제 단계 (Cleaning Step)\n",
    "- 토큰화 단계 (Tokenize Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 토큰화 관련 모듈\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 파일\n",
    "DATA_FILE   = '../data/test_data.txt'           ## 말뭉치 즉 코퍼스(Copous)     \n",
    "STOP_WORD   = stopwords.words('english')        ## 불용어 즉, 분석에 의미없는 단어들\n",
    "PUNCTUATION = punctuation                       ## 구두점\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP_WORD   : 198개\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n",
      "PUNCTUATION : 32개\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(f'STOP_WORD   : {len(STOP_WORD)}개\\n{STOP_WORD}')\n",
    "print(f'PUNCTUATION : {len(PUNCTUATION)}개\\n{PUNCTUATION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 텍스트 데이터 정제<hr>\n",
    "- 영어 : 대소문자 일치\n",
    "- 필요없는 기호, 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileData==> 1851개\n"
     ]
    }
   ],
   "source": [
    "## - 파일 데이터 읽어오기\n",
    "with open(DATA_FILE, mode='r', encoding='utf-8') as f:\n",
    "    fileData=f.read()\n",
    "\n",
    "##- 확인\n",
    "print(f'fileData==> {len(fileData)}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileData==>\n",
      " what a merry-go-round is the e\n"
     ]
    }
   ],
   "source": [
    "## 대소문자 일치 ==> 소문자\n",
    "fileData=fileData.lower()\n",
    "\n",
    "##- 확인\n",
    "print(f'fileData==>\\n {fileData[:30]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 문장 단위 토큰화 + 불용어 제거 + 원형 복원 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what a merry-go-round is the eighteenth collection by british fashion designer alexander mcqueen, made for the autumn/winter 2001 season of his fashion house alexander mcqueen.',\n",
       " \"the collection drew on imagery of clowns and carnivals, inspired by mcqueen's feelings about childhood and his experiences in the fashion industry.\",\n",
       " 'the designs were influenced by military chic, cinema such as nosferatu (1922) and cabaret (1972), 1920s flapper fashion, and the french revolution.',\n",
       " 'the palette comprised dark colours complemented with neutrals and muted greens.',\n",
       " 'the show marked the first appearance of the skull motif that became a signature of the brand.',\n",
       " \"the collection's runway show was staged on 21 february 2001 at the gatliff road warehouse in london, as part of london fashion week.\",\n",
       " \"it was mcqueen's final show in london; all his future collections were presented in paris.\",\n",
       " 'sixty-two looks were presented in the main runway show, with at least six more in the finale.',\n",
       " '[a] the show was staged in a dark room with a carousel at the centre.',\n",
       " 'during the finale, the lights came up to reveal piles of discarded childhood bric-à-brac at the rear of the stage, while models dressed as evil clowns cavorted around the stage, posing in their eveningwear.',\n",
       " 'critical response to the collection was generally positive, and it has attracted some academic analysis for the theme and messaging.',\n",
       " \"like mcqueen's previous show voss (spring/summer 2001), merry-go-round served as a critique of the fashion industry, which he sometimes described as toxic and suffocating.\",\n",
       " 'it contained elements that several authors have taken as references to french luxury goods conglomerate lvmh and its management, with whom mcqueen had a turbulent relationship.',\n",
       " 'ensembles from merry-go-round have appeared in exhibitions such as the mcqueen retrospective alexander mcqueen: savage beauty.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [3-1] 문장 분리 후 문장 단위에서 토큰 분리\n",
    "sentences = sent_tokenize(fileData)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------------------------------------------------\n",
    "## 함수기능 : 품사 기반 불필요 품사 제거 + 원형 복원 토큰 반환 \n",
    "## 함수이름 : covertOriginal\n",
    "## 매개변수 : pos_token_list - (단어, 품사)형태의 토큰 리스트\n",
    "## 함수결과 : 불필요 품사 제거 + 원형 복원 토큰 리스트\n",
    "## --------------------------------------------------------------\n",
    "def covertOriginal(pos_token_list):\n",
    "    ## 표제어 추출 인스턴스\n",
    "    wnLemma = WordNetLemmatizer()\n",
    "\n",
    "    ## 원형 복원 저장 \n",
    "    result =[]\n",
    "    print(pos_token_list)\n",
    "    ## 형용사, 동사 경우 표제어 즉, 원형 복원\n",
    "    for word, pos in pos_token_list:\n",
    "            \n",
    "        ## 형용사, 동사 경우 표제어 즉, 원형 복원\n",
    "        if pos[:2] in ['JJ', 'VB']:\n",
    "            result.append(wnLemma.lemmatize(word, 'a' if pos=='JJ' else 'v' ))\n",
    "        elif pos not in ['DT', 'IN', 'CD', 'CC']:\n",
    "            ## 토큰 합치기 => 불필요한 품사 제거한 토큰들 그대로 추가\n",
    "            result.append(word)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP'), ('a', 'DT'), ('merrygoround', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('eighteenth', 'JJ'), ('collection', 'NN'), ('by', 'IN'), ('british', 'JJ'), ('fashion', 'NN'), ('designer', 'NN'), ('alexander', 'NN'), ('mcqueen', 'NN'), ('made', 'VBN'), ('for', 'IN'), ('the', 'DT'), ('autumnwinter', 'NN'), ('2001', 'CD'), ('season', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('fashion', 'NN'), ('house', 'NN'), ('alexander', 'NN'), ('mcqueen', 'NN')]\n",
      "[('what', 'WP'), ('a', 'DT'), ('merrygoround', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('eighteenth', 'JJ'), ('collection', 'NN'), ('by', 'IN'), ('british', 'JJ'), ('fashion', 'NN'), ('designer', 'NN'), ('alexander', 'NN'), ('mcqueen', 'NN'), ('made', 'VBN'), ('for', 'IN'), ('the', 'DT'), ('autumnwinter', 'NN'), ('2001', 'CD'), ('season', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('fashion', 'NN'), ('house', 'NN'), ('alexander', 'NN'), ('mcqueen', 'NN')]\n",
      "['what', 'merrygoround', 'be', 'eighteenth', 'collection', 'british', 'fashion', 'designer', 'alexander', 'mcqueen', 'make', 'autumnwinter', 'season', 'his', 'fashion', 'house', 'alexander', 'mcqueen']\n",
      "[('the', 'DT'), ('collection', 'NN'), ('drew', 'VBD'), ('on', 'IN'), ('imagery', 'NN'), ('of', 'IN'), ('clowns', 'NNS'), ('and', 'CC'), ('carnivals', 'NNS'), ('inspired', 'VBN'), ('by', 'IN'), ('mcqueens', 'NNS'), ('feelings', 'NNS'), ('about', 'IN'), ('childhood', 'NN'), ('and', 'CC'), ('his', 'PRP$'), ('experiences', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('fashion', 'NN'), ('industry', 'NN')]\n",
      "[('the', 'DT'), ('collection', 'NN'), ('drew', 'VBD'), ('on', 'IN'), ('imagery', 'NN'), ('of', 'IN'), ('clowns', 'NNS'), ('and', 'CC'), ('carnivals', 'NNS'), ('inspired', 'VBN'), ('by', 'IN'), ('mcqueens', 'NNS'), ('feelings', 'NNS'), ('about', 'IN'), ('childhood', 'NN'), ('and', 'CC'), ('his', 'PRP$'), ('experiences', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('fashion', 'NN'), ('industry', 'NN')]\n",
      "['collection', 'draw', 'imagery', 'clowns', 'carnivals', 'inspire', 'mcqueens', 'feelings', 'childhood', 'his', 'experiences', 'fashion', 'industry']\n",
      "[('the', 'DT'), ('designs', 'NNS'), ('were', 'VBD'), ('influenced', 'VBN'), ('by', 'IN'), ('military', 'JJ'), ('chic', 'JJ'), ('cinema', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('nosferatu', 'JJ'), ('1922', 'CD'), ('and', 'CC'), ('cabaret', 'VB'), ('1972', 'CD'), ('1920s', 'CD'), ('flapper', 'JJ'), ('fashion', 'NN'), ('and', 'CC'), ('the', 'DT'), ('french', 'JJ'), ('revolution', 'NN')]\n",
      "[('the', 'DT'), ('designs', 'NNS'), ('were', 'VBD'), ('influenced', 'VBN'), ('by', 'IN'), ('military', 'JJ'), ('chic', 'JJ'), ('cinema', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('nosferatu', 'JJ'), ('1922', 'CD'), ('and', 'CC'), ('cabaret', 'VB'), ('1972', 'CD'), ('1920s', 'CD'), ('flapper', 'JJ'), ('fashion', 'NN'), ('and', 'CC'), ('the', 'DT'), ('french', 'JJ'), ('revolution', 'NN')]\n",
      "['designs', 'be', 'influence', 'military', 'chic', 'cinema', 'such', 'nosferatu', 'cabaret', 'flapper', 'fashion', 'french', 'revolution']\n",
      "[('the', 'DT'), ('palette', 'NN'), ('comprised', 'VBD'), ('dark', 'JJ'), ('colours', 'NNS'), ('complemented', 'VBN'), ('with', 'IN'), ('neutrals', 'NNS'), ('and', 'CC'), ('muted', 'VBD'), ('greens', 'NNS')]\n",
      "[('the', 'DT'), ('palette', 'NN'), ('comprised', 'VBD'), ('dark', 'JJ'), ('colours', 'NNS'), ('complemented', 'VBN'), ('with', 'IN'), ('neutrals', 'NNS'), ('and', 'CC'), ('muted', 'VBD'), ('greens', 'NNS')]\n",
      "['palette', 'comprise', 'dark', 'colours', 'complement', 'neutrals', 'mute', 'greens']\n",
      "[('the', 'DT'), ('show', 'NN'), ('marked', 'VBD'), ('the', 'DT'), ('first', 'JJ'), ('appearance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('skull', 'NN'), ('motif', 'NN'), ('that', 'WDT'), ('became', 'VBD'), ('a', 'DT'), ('signature', 'NN'), ('of', 'IN'), ('the', 'DT'), ('brand', 'NN')]\n",
      "[('the', 'DT'), ('show', 'NN'), ('marked', 'VBD'), ('the', 'DT'), ('first', 'JJ'), ('appearance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('skull', 'NN'), ('motif', 'NN'), ('that', 'WDT'), ('became', 'VBD'), ('a', 'DT'), ('signature', 'NN'), ('of', 'IN'), ('the', 'DT'), ('brand', 'NN')]\n",
      "['show', 'mark', 'first', 'appearance', 'skull', 'motif', 'that', 'become', 'signature', 'brand']\n",
      "[('the', 'DT'), ('collections', 'NNS'), ('runway', 'VBP'), ('show', 'NN'), ('was', 'VBD'), ('staged', 'VBN'), ('on', 'IN'), ('21', 'CD'), ('february', 'JJ'), ('2001', 'CD'), ('at', 'IN'), ('the', 'DT'), ('gatliff', 'NN'), ('road', 'NN'), ('warehouse', 'NN'), ('in', 'IN'), ('london', 'NN'), ('as', 'IN'), ('part', 'NN'), ('of', 'IN'), ('london', 'JJ'), ('fashion', 'NN'), ('week', 'NN')]\n",
      "[('the', 'DT'), ('collections', 'NNS'), ('runway', 'VBP'), ('show', 'NN'), ('was', 'VBD'), ('staged', 'VBN'), ('on', 'IN'), ('21', 'CD'), ('february', 'JJ'), ('2001', 'CD'), ('at', 'IN'), ('the', 'DT'), ('gatliff', 'NN'), ('road', 'NN'), ('warehouse', 'NN'), ('in', 'IN'), ('london', 'NN'), ('as', 'IN'), ('part', 'NN'), ('of', 'IN'), ('london', 'JJ'), ('fashion', 'NN'), ('week', 'NN')]\n",
      "['collections', 'runway', 'show', 'be', 'stag', 'february', 'gatliff', 'road', 'warehouse', 'london', 'part', 'london', 'fashion', 'week']\n",
      "[('it', 'PRP'), ('was', 'VBD'), ('mcqueens', 'JJ'), ('final', 'JJ'), ('show', 'NN'), ('in', 'IN'), ('london', 'NN'), ('all', 'PDT'), ('his', 'PRP$'), ('future', 'JJ'), ('collections', 'NNS'), ('were', 'VBD'), ('presented', 'VBN'), ('in', 'IN'), ('paris', 'NN')]\n",
      "[('it', 'PRP'), ('was', 'VBD'), ('mcqueens', 'JJ'), ('final', 'JJ'), ('show', 'NN'), ('in', 'IN'), ('london', 'NN'), ('all', 'PDT'), ('his', 'PRP$'), ('future', 'JJ'), ('collections', 'NNS'), ('were', 'VBD'), ('presented', 'VBN'), ('in', 'IN'), ('paris', 'NN')]\n",
      "['it', 'be', 'mcqueens', 'final', 'show', 'london', 'all', 'his', 'future', 'collections', 'be', 'present', 'paris']\n",
      "[('sixtytwo', 'JJ'), ('looks', 'NNS'), ('were', 'VBD'), ('presented', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('main', 'JJ'), ('runway', 'NN'), ('show', 'NN'), ('with', 'IN'), ('at', 'IN'), ('least', 'JJS'), ('six', 'CD'), ('more', 'JJR'), ('in', 'IN'), ('the', 'DT'), ('finale', 'NN')]\n",
      "[('sixtytwo', 'JJ'), ('looks', 'NNS'), ('were', 'VBD'), ('presented', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('main', 'JJ'), ('runway', 'NN'), ('show', 'NN'), ('with', 'IN'), ('at', 'IN'), ('least', 'JJS'), ('six', 'CD'), ('more', 'JJR'), ('in', 'IN'), ('the', 'DT'), ('finale', 'NN')]\n",
      "['sixtytwo', 'looks', 'be', 'present', 'main', 'runway', 'show', 'least', 'more', 'finale']\n",
      "[('a', 'DT'), ('the', 'DT'), ('show', 'NN'), ('was', 'VBD'), ('staged', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('dark', 'JJ'), ('room', 'NN'), ('with', 'IN'), ('a', 'DT'), ('carousel', 'NN'), ('at', 'IN'), ('the', 'DT'), ('centre', 'NN')]\n",
      "[('a', 'DT'), ('the', 'DT'), ('show', 'NN'), ('was', 'VBD'), ('staged', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('dark', 'JJ'), ('room', 'NN'), ('with', 'IN'), ('a', 'DT'), ('carousel', 'NN'), ('at', 'IN'), ('the', 'DT'), ('centre', 'NN')]\n",
      "['show', 'be', 'stag', 'dark', 'room', 'carousel', 'centre']\n",
      "[('during', 'IN'), ('the', 'DT'), ('finale', 'NN'), ('the', 'DT'), ('lights', 'NNS'), ('came', 'VBD'), ('up', 'RB'), ('to', 'TO'), ('reveal', 'VB'), ('piles', 'NNS'), ('of', 'IN'), ('discarded', 'JJ'), ('childhood', 'NN'), ('bricàbrac', 'NN'), ('at', 'IN'), ('the', 'DT'), ('rear', 'NN'), ('of', 'IN'), ('the', 'DT'), ('stage', 'NN'), ('while', 'IN'), ('models', 'NNS'), ('dressed', 'VBN'), ('as', 'IN'), ('evil', 'JJ'), ('clowns', 'NNS'), ('cavorted', 'VBN'), ('around', 'IN'), ('the', 'DT'), ('stage', 'NN'), ('posing', 'VBG'), ('in', 'IN'), ('their', 'PRP$'), ('eveningwear', 'NN')]\n",
      "[('during', 'IN'), ('the', 'DT'), ('finale', 'NN'), ('the', 'DT'), ('lights', 'NNS'), ('came', 'VBD'), ('up', 'RB'), ('to', 'TO'), ('reveal', 'VB'), ('piles', 'NNS'), ('of', 'IN'), ('discarded', 'JJ'), ('childhood', 'NN'), ('bricàbrac', 'NN'), ('at', 'IN'), ('the', 'DT'), ('rear', 'NN'), ('of', 'IN'), ('the', 'DT'), ('stage', 'NN'), ('while', 'IN'), ('models', 'NNS'), ('dressed', 'VBN'), ('as', 'IN'), ('evil', 'JJ'), ('clowns', 'NNS'), ('cavorted', 'VBN'), ('around', 'IN'), ('the', 'DT'), ('stage', 'NN'), ('posing', 'VBG'), ('in', 'IN'), ('their', 'PRP$'), ('eveningwear', 'NN')]\n",
      "['finale', 'lights', 'come', 'up', 'to', 'reveal', 'piles', 'discarded', 'childhood', 'bricàbrac', 'rear', 'stage', 'models', 'dress', 'evil', 'clowns', 'cavort', 'stage', 'pose', 'their', 'eveningwear']\n",
      "[('critical', 'JJ'), ('response', 'NN'), ('to', 'TO'), ('the', 'DT'), ('collection', 'NN'), ('was', 'VBD'), ('generally', 'RB'), ('positive', 'JJ'), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('attracted', 'VBN'), ('some', 'DT'), ('academic', 'JJ'), ('analysis', 'NN'), ('for', 'IN'), ('the', 'DT'), ('theme', 'NN'), ('and', 'CC'), ('messaging', 'NN')]\n",
      "[('critical', 'JJ'), ('response', 'NN'), ('to', 'TO'), ('the', 'DT'), ('collection', 'NN'), ('was', 'VBD'), ('generally', 'RB'), ('positive', 'JJ'), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('attracted', 'VBN'), ('some', 'DT'), ('academic', 'JJ'), ('analysis', 'NN'), ('for', 'IN'), ('the', 'DT'), ('theme', 'NN'), ('and', 'CC'), ('messaging', 'NN')]\n",
      "['critical', 'response', 'to', 'collection', 'be', 'generally', 'positive', 'it', 'have', 'attract', 'academic', 'analysis', 'theme', 'messaging']\n",
      "[('like', 'IN'), ('mcqueens', 'NNS'), ('previous', 'JJ'), ('show', 'NN'), ('voss', 'IN'), ('springsummer', 'NN'), ('2001', 'CD'), ('merrygoround', 'NN'), ('served', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('critique', 'NN'), ('of', 'IN'), ('the', 'DT'), ('fashion', 'NN'), ('industry', 'NN'), ('which', 'WDT'), ('he', 'PRP'), ('sometimes', 'RB'), ('described', 'VBD'), ('as', 'IN'), ('toxic', 'NN'), ('and', 'CC'), ('suffocating', 'NN')]\n",
      "[('like', 'IN'), ('mcqueens', 'NNS'), ('previous', 'JJ'), ('show', 'NN'), ('voss', 'IN'), ('springsummer', 'NN'), ('2001', 'CD'), ('merrygoround', 'NN'), ('served', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('critique', 'NN'), ('of', 'IN'), ('the', 'DT'), ('fashion', 'NN'), ('industry', 'NN'), ('which', 'WDT'), ('he', 'PRP'), ('sometimes', 'RB'), ('described', 'VBD'), ('as', 'IN'), ('toxic', 'NN'), ('and', 'CC'), ('suffocating', 'NN')]\n",
      "['mcqueens', 'previous', 'show', 'springsummer', 'merrygoround', 'serve', 'critique', 'fashion', 'industry', 'which', 'he', 'sometimes', 'describe', 'toxic', 'suffocating']\n",
      "[('it', 'PRP'), ('contained', 'VBD'), ('elements', 'NNS'), ('that', 'IN'), ('several', 'JJ'), ('authors', 'NNS'), ('have', 'VBP'), ('taken', 'VBN'), ('as', 'IN'), ('references', 'NNS'), ('to', 'TO'), ('french', 'JJ'), ('luxury', 'NN'), ('goods', 'NNS'), ('conglomerate', 'VBP'), ('lvmh', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('management', 'NN'), ('with', 'IN'), ('whom', 'WP'), ('mcqueen', 'NN'), ('had', 'VBD'), ('a', 'DT'), ('turbulent', 'NN'), ('relationship', 'NN')]\n",
      "[('it', 'PRP'), ('contained', 'VBD'), ('elements', 'NNS'), ('that', 'IN'), ('several', 'JJ'), ('authors', 'NNS'), ('have', 'VBP'), ('taken', 'VBN'), ('as', 'IN'), ('references', 'NNS'), ('to', 'TO'), ('french', 'JJ'), ('luxury', 'NN'), ('goods', 'NNS'), ('conglomerate', 'VBP'), ('lvmh', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('management', 'NN'), ('with', 'IN'), ('whom', 'WP'), ('mcqueen', 'NN'), ('had', 'VBD'), ('a', 'DT'), ('turbulent', 'NN'), ('relationship', 'NN')]\n",
      "['it', 'contain', 'elements', 'several', 'authors', 'have', 'take', 'references', 'to', 'french', 'luxury', 'goods', 'conglomerate', 'lvmh', 'its', 'management', 'whom', 'mcqueen', 'have', 'turbulent', 'relationship']\n",
      "[('ensembles', 'NNS'), ('from', 'IN'), ('merrygoround', 'NN'), ('have', 'VBP'), ('appeared', 'VBN'), ('in', 'IN'), ('exhibitions', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('the', 'DT'), ('mcqueen', 'JJ'), ('retrospective', 'JJ'), ('alexander', 'NN'), ('mcqueen', 'JJ'), ('savage', 'NN'), ('beauty', 'NN')]\n",
      "[('ensembles', 'NNS'), ('from', 'IN'), ('merrygoround', 'NN'), ('have', 'VBP'), ('appeared', 'VBN'), ('in', 'IN'), ('exhibitions', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('the', 'DT'), ('mcqueen', 'JJ'), ('retrospective', 'JJ'), ('alexander', 'NN'), ('mcqueen', 'JJ'), ('savage', 'NN'), ('beauty', 'NN')]\n",
      "['ensembles', 'merrygoround', 'have', 'appear', 'exhibitions', 'such', 'mcqueen', 'retrospective', 'alexander', 'mcqueen', 'savage', 'beauty']\n",
      "총 문장 수 : 14개\n",
      "[['merrygoround', 'eighteenth', 'collection', 'british', 'fashion', 'designer', 'alexander', 'mcqueen', 'make', 'autumnwinter', 'season', 'fashion', 'house', 'alexander', 'mcqueen'], ['collection', 'draw', 'imagery', 'clowns', 'carnivals', 'inspire', 'mcqueens', 'feelings', 'childhood', 'experiences', 'fashion', 'industry'], ['designs', 'influence', 'military', 'chic', 'cinema', 'nosferatu', 'cabaret', 'flapper', 'fashion', 'french', 'revolution'], ['palette', 'comprise', 'dark', 'colours', 'complement', 'neutrals', 'mute', 'greens'], ['show', 'mark', 'first', 'appearance', 'skull', 'motif', 'become', 'signature', 'brand'], ['collections', 'runway', 'show', 'stag', 'february', 'gatliff', 'road', 'warehouse', 'london', 'part', 'london', 'fashion', 'week'], ['mcqueens', 'final', 'show', 'london', 'future', 'collections', 'present', 'paris'], ['sixtytwo', 'looks', 'present', 'main', 'runway', 'show', 'least', 'finale'], ['show', 'stag', 'dark', 'room', 'carousel', 'centre'], ['finale', 'lights', 'come', 'reveal', 'piles', 'discarded', 'childhood', 'bricàbrac', 'rear', 'stage', 'models', 'dress', 'evil', 'clowns', 'cavort', 'stage', 'pose', 'eveningwear'], ['critical', 'response', 'collection', 'generally', 'positive', 'attract', 'academic', 'analysis', 'theme', 'messaging'], ['mcqueens', 'previous', 'show', 'springsummer', 'merrygoround', 'serve', 'critique', 'fashion', 'industry', 'sometimes', 'describe', 'toxic', 'suffocating'], ['contain', 'elements', 'several', 'authors', 'take', 'references', 'french', 'luxury', 'goods', 'conglomerate', 'lvmh', 'management', 'mcqueen', 'turbulent', 'relationship'], ['ensembles', 'merrygoround', 'appear', 'exhibitions', 'mcqueen', 'retrospective', 'alexander', 'mcqueen', 'savage', 'beauty']]\n"
     ]
    }
   ],
   "source": [
    "## [3-2] 문장 단위 전처리 된 문장 리스트 추출 \n",
    "\n",
    "## - 문장별 토큰 리스트, 품사 토큰 리스트 저장 \n",
    "sent_token_list, pos_token_list =[],[]\n",
    "\n",
    "## - 문장별 토큰화 처리\n",
    "for sent in sentences:\n",
    "    ## 문장 단위로 구두점 제거, 토큰 분리\n",
    "    for p in PUNCTUATION: \n",
    "        if p in sent: sent=sent.replace(p,'')\n",
    "    \n",
    "    ## 토큰 분리=> list 반환\n",
    "    pos_token_list = pos_tag( word_tokenize(sent) )\n",
    "    print(pos_token_list)\n",
    "\n",
    "    ## 형용사 'JJ'=> 'a', 동사 'VB' => 'v'원형 복원 \n",
    "    ## 불필요한 품사 제거한 토큰들 저장\n",
    "    tokens = covertOriginal(pos_token_list)\n",
    "    print(tokens)\n",
    "\n",
    "    ## 토큰 리스트에서 불용어 제거\n",
    "    words = [ w for w in tokens  if w not in STOP_WORD ]\n",
    "\n",
    "    ## 문장 단위 토큰 저장 \n",
    "    sent_token_list.append(words)\n",
    "    \n",
    "print(F'총 문장 수 : {len(sent_token_list)}개\\n{sent_token_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 단어 사전 생성 <hr>\n",
    "- 토큰 -- 정수 인코딩\n",
    "- 특수토큰 : 없는 토큰 UNK, 길이 맞춤용 토큰 PAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4-1) 중복 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_list => ['merrygoround', 'eighteenth', 'collection', 'british', 'fashion', 'designer', 'alexander', 'mcqueen', 'make', 'autumnwinter', 'season', 'fashion', 'house', 'alexander', 'mcqueen', 'collection', 'draw', 'imagery', 'clowns', 'carnivals', 'inspire', 'mcqueens', 'feelings', 'childhood', 'experiences', 'fashion', 'industry', 'designs', 'influence', 'military', 'chic', 'cinema', 'nosferatu', 'cabaret', 'flapper', 'fashion', 'french', 'revolution', 'palette', 'comprise', 'dark', 'colours', 'complement', 'neutrals', 'mute', 'greens', 'show', 'mark', 'first', 'appearance', 'skull', 'motif', 'become', 'signature', 'brand', 'collections', 'runway', 'show', 'stag', 'february', 'gatliff', 'road', 'warehouse', 'london', 'part', 'london', 'fashion', 'week', 'mcqueens', 'final', 'show', 'london', 'future', 'collections', 'present', 'paris', 'sixtytwo', 'looks', 'present', 'main', 'runway', 'show', 'least', 'finale', 'show', 'stag', 'dark', 'room', 'carousel', 'centre', 'finale', 'lights', 'come', 'reveal', 'piles', 'discarded', 'childhood', 'bricàbrac', 'rear', 'stage', 'models', 'dress', 'evil', 'clowns', 'cavort', 'stage', 'pose', 'eveningwear', 'critical', 'response', 'collection', 'generally', 'positive', 'attract', 'academic', 'analysis', 'theme', 'messaging', 'mcqueens', 'previous', 'show', 'springsummer', 'merrygoround', 'serve', 'critique', 'fashion', 'industry', 'sometimes', 'describe', 'toxic', 'suffocating', 'contain', 'elements', 'several', 'authors', 'take', 'references', 'french', 'luxury', 'goods', 'conglomerate', 'lvmh', 'management', 'mcqueen', 'turbulent', 'relationship', 'ensembles', 'merrygoround', 'appear', 'exhibitions', 'mcqueen', 'retrospective', 'alexander', 'mcqueen', 'savage', 'beauty']\n",
      "token_list => 156개\n",
      "token_list => ['greens', 'pose', 'authors', 'rear', 'brand', 'flapper', 'neutrals', 'influence', 'stag', 'critical', 'merrygoround', 'evil', 'week', 'french', 'management', 'feelings', 'ensembles', 'nosferatu', 'centre', 'present', 'retrospective', 'bricàbrac', 'mute', 'comprise', 'least', 'autumnwinter', 'cabaret', 'industry', 'become', 'signature', 'discarded', 'take', 'complement', 'positive', 'room', 'designs', 'collections', 'experiences', 'part', 'conglomerate', 'palette', 'mcqueens', 'inspire', 'relationship', 'dress', 'attract', 'imagery', 'british', 'mark', 'come', 'road', 'suffocating', 'serve', 'piles', 'final', 'gatliff', 'academic', 'designer', 'cinema', 'lvmh', 'make', 'springsummer', 'luxury', 'carousel', 'paris', 'toxic', 'eveningwear', 'contain', 'show', 'first', 'chic', 'appear', 'revolution', 'response', 'sometimes', 'turbulent', 'alexander', 'eighteenth', 'collection', 'dark', 'sixtytwo', 'beauty', 'exhibitions', 'military', 'reveal', 'several', 'skull', 'future', 'generally', 'messaging', 'goods', 'previous', 'describe', 'analysis', 'runway', 'models', 'finale', 'season', 'colours', 'main', 'lights', 'appearance', 'house', 'savage', 'stage', 'cavort', 'london', 'february', 'references', 'draw', 'mcqueen', 'warehouse', 'looks', 'clowns', 'childhood', 'carnivals', 'motif', 'fashion', 'theme', 'critique', 'elements']\n",
      "token_list => 121개\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## - 문장의 토큰들 하나로 합치기\n",
    "token_list = [ word  for sent in sent_token_list  for word in sent  ]\n",
    "\n",
    "print(f'token_list => {token_list}')\n",
    "print(f'token_list => {len(token_list)}개')\n",
    "\n",
    "## - 토큰들 중복 제거\n",
    "token_list = list(set(token_list))\n",
    "print(f'token_list => {token_list}')\n",
    "print(f'token_list => {len(token_list)}개')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4-2) 단어 사전 생성<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0, '<UNK>': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dict 타입으로 단어사전 생성\n",
    "VOCAB_TO_IDX = {'<PAD>':0, '<UNK>':1 }\n",
    "VOCAB_TO_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 토큰들에게 정수 숫자 부여\n",
    "for idx, token in enumerate(token_list, 2):\n",
    "    VOCAB_TO_IDX[token]=idx \n",
    "\n",
    "## idx => word로 변환\n",
    "IDX_TO_TOKEN = {v:k for k,v in VOCAB_TO_IDX.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_TO_IDX=>\n",
      " {'<PAD>': 0, '<UNK>': 1, 'greens': 2, 'pose': 3, 'authors': 4, 'rear': 5, 'brand': 6, 'flapper': 7, 'neutrals': 8, 'influence': 9, 'stag': 10, 'critical': 11, 'merrygoround': 12, 'evil': 13, 'week': 14, 'french': 15, 'management': 16, 'feelings': 17, 'ensembles': 18, 'nosferatu': 19, 'centre': 20, 'present': 21, 'retrospective': 22, 'bricàbrac': 23, 'mute': 24, 'comprise': 25, 'least': 26, 'autumnwinter': 27, 'cabaret': 28, 'industry': 29, 'become': 30, 'signature': 31, 'discarded': 32, 'take': 33, 'complement': 34, 'positive': 35, 'room': 36, 'designs': 37, 'collections': 38, 'experiences': 39, 'part': 40, 'conglomerate': 41, 'palette': 42, 'mcqueens': 43, 'inspire': 44, 'relationship': 45, 'dress': 46, 'attract': 47, 'imagery': 48, 'british': 49, 'mark': 50, 'come': 51, 'road': 52, 'suffocating': 53, 'serve': 54, 'piles': 55, 'final': 56, 'gatliff': 57, 'academic': 58, 'designer': 59, 'cinema': 60, 'lvmh': 61, 'make': 62, 'springsummer': 63, 'luxury': 64, 'carousel': 65, 'paris': 66, 'toxic': 67, 'eveningwear': 68, 'contain': 69, 'show': 70, 'first': 71, 'chic': 72, 'appear': 73, 'revolution': 74, 'response': 75, 'sometimes': 76, 'turbulent': 77, 'alexander': 78, 'eighteenth': 79, 'collection': 80, 'dark': 81, 'sixtytwo': 82, 'beauty': 83, 'exhibitions': 84, 'military': 85, 'reveal': 86, 'several': 87, 'skull': 88, 'future': 89, 'generally': 90, 'messaging': 91, 'goods': 92, 'previous': 93, 'describe': 94, 'analysis': 95, 'runway': 96, 'models': 97, 'finale': 98, 'season': 99, 'colours': 100, 'main': 101, 'lights': 102, 'appearance': 103, 'house': 104, 'savage': 105, 'stage': 106, 'cavort': 107, 'london': 108, 'february': 109, 'references': 110, 'draw': 111, 'mcqueen': 112, 'warehouse': 113, 'looks': 114, 'clowns': 115, 'childhood': 116, 'carnivals': 117, 'motif': 118, 'fashion': 119, 'theme': 120, 'critique': 121, 'elements': 122}\n",
      "IDX_TO_TOKEN=>\n",
      " {0: '<PAD>', 1: '<UNK>', 2: 'greens', 3: 'pose', 4: 'authors', 5: 'rear', 6: 'brand', 7: 'flapper', 8: 'neutrals', 9: 'influence', 10: 'stag', 11: 'critical', 12: 'merrygoround', 13: 'evil', 14: 'week', 15: 'french', 16: 'management', 17: 'feelings', 18: 'ensembles', 19: 'nosferatu', 20: 'centre', 21: 'present', 22: 'retrospective', 23: 'bricàbrac', 24: 'mute', 25: 'comprise', 26: 'least', 27: 'autumnwinter', 28: 'cabaret', 29: 'industry', 30: 'become', 31: 'signature', 32: 'discarded', 33: 'take', 34: 'complement', 35: 'positive', 36: 'room', 37: 'designs', 38: 'collections', 39: 'experiences', 40: 'part', 41: 'conglomerate', 42: 'palette', 43: 'mcqueens', 44: 'inspire', 45: 'relationship', 46: 'dress', 47: 'attract', 48: 'imagery', 49: 'british', 50: 'mark', 51: 'come', 52: 'road', 53: 'suffocating', 54: 'serve', 55: 'piles', 56: 'final', 57: 'gatliff', 58: 'academic', 59: 'designer', 60: 'cinema', 61: 'lvmh', 62: 'make', 63: 'springsummer', 64: 'luxury', 65: 'carousel', 66: 'paris', 67: 'toxic', 68: 'eveningwear', 69: 'contain', 70: 'show', 71: 'first', 72: 'chic', 73: 'appear', 74: 'revolution', 75: 'response', 76: 'sometimes', 77: 'turbulent', 78: 'alexander', 79: 'eighteenth', 80: 'collection', 81: 'dark', 82: 'sixtytwo', 83: 'beauty', 84: 'exhibitions', 85: 'military', 86: 'reveal', 87: 'several', 88: 'skull', 89: 'future', 90: 'generally', 91: 'messaging', 92: 'goods', 93: 'previous', 94: 'describe', 95: 'analysis', 96: 'runway', 97: 'models', 98: 'finale', 99: 'season', 100: 'colours', 101: 'main', 102: 'lights', 103: 'appearance', 104: 'house', 105: 'savage', 106: 'stage', 107: 'cavort', 108: 'london', 109: 'february', 110: 'references', 111: 'draw', 112: 'mcqueen', 113: 'warehouse', 114: 'looks', 115: 'clowns', 116: 'childhood', 117: 'carnivals', 118: 'motif', 119: 'fashion', 120: 'theme', 121: 'critique', 122: 'elements'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('VOCAB_TO_IDX=>\\n', VOCAB_TO_IDX)\n",
    "print('IDX_TO_TOKEN=>\\n', IDX_TO_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 자연어 => 숫자 변환 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[문장] ['merrygoround', 'eighteenth', 'collection', 'british', 'fashion', 'designer', 'alexander', 'mcqueen', 'make', 'autumnwinter', 'season', 'fashion', 'house', 'alexander', 'mcqueen']\n",
      "[수치] [12, 79, 80, 49, 119, 59, 78, 112, 62, 27, 99, 119, 104, 78, 112]\n",
      "\n",
      "[문장] ['collection', 'draw', 'imagery', 'clowns', 'carnivals', 'inspire', 'mcqueens', 'feelings', 'childhood', 'experiences', 'fashion', 'industry']\n",
      "[수치] [80, 111, 48, 115, 117, 44, 43, 17, 116, 39, 119, 29]\n",
      "\n",
      "[문장] ['designs', 'influence', 'military', 'chic', 'cinema', 'nosferatu', 'cabaret', 'flapper', 'fashion', 'french', 'revolution']\n",
      "[수치] [37, 9, 85, 72, 60, 19, 28, 7, 119, 15, 74]\n",
      "\n",
      "[문장] ['palette', 'comprise', 'dark', 'colours', 'complement', 'neutrals', 'mute', 'greens']\n",
      "[수치] [42, 25, 81, 100, 34, 8, 24, 2]\n",
      "\n",
      "[문장] ['show', 'mark', 'first', 'appearance', 'skull', 'motif', 'become', 'signature', 'brand']\n",
      "[수치] [70, 50, 71, 103, 88, 118, 30, 31, 6]\n",
      "\n",
      "[문장] ['collections', 'runway', 'show', 'stag', 'february', 'gatliff', 'road', 'warehouse', 'london', 'part', 'london', 'fashion', 'week']\n",
      "[수치] [38, 96, 70, 10, 109, 57, 52, 113, 108, 40, 108, 119, 14]\n",
      "\n",
      "[문장] ['mcqueens', 'final', 'show', 'london', 'future', 'collections', 'present', 'paris']\n",
      "[수치] [43, 56, 70, 108, 89, 38, 21, 66]\n",
      "\n",
      "[문장] ['sixtytwo', 'looks', 'present', 'main', 'runway', 'show', 'least', 'finale']\n",
      "[수치] [82, 114, 21, 101, 96, 70, 26, 98]\n",
      "\n",
      "[문장] ['show', 'stag', 'dark', 'room', 'carousel', 'centre']\n",
      "[수치] [70, 10, 81, 36, 65, 20]\n",
      "\n",
      "[문장] ['finale', 'lights', 'come', 'reveal', 'piles', 'discarded', 'childhood', 'bricàbrac', 'rear', 'stage', 'models', 'dress', 'evil', 'clowns', 'cavort', 'stage', 'pose', 'eveningwear']\n",
      "[수치] [98, 102, 51, 86, 55, 32, 116, 23, 5, 106, 97, 46, 13, 115, 107, 106, 3, 68]\n",
      "\n",
      "[문장] ['critical', 'response', 'collection', 'generally', 'positive', 'attract', 'academic', 'analysis', 'theme', 'messaging']\n",
      "[수치] [11, 75, 80, 90, 35, 47, 58, 95, 120, 91]\n",
      "\n",
      "[문장] ['mcqueens', 'previous', 'show', 'springsummer', 'merrygoround', 'serve', 'critique', 'fashion', 'industry', 'sometimes', 'describe', 'toxic', 'suffocating']\n",
      "[수치] [43, 93, 70, 63, 12, 54, 121, 119, 29, 76, 94, 67, 53]\n",
      "\n",
      "[문장] ['contain', 'elements', 'several', 'authors', 'take', 'references', 'french', 'luxury', 'goods', 'conglomerate', 'lvmh', 'management', 'mcqueen', 'turbulent', 'relationship']\n",
      "[수치] [69, 122, 87, 4, 33, 110, 15, 64, 92, 41, 61, 16, 112, 77, 45]\n",
      "\n",
      "[문장] ['ensembles', 'merrygoround', 'appear', 'exhibitions', 'mcqueen', 'retrospective', 'alexander', 'mcqueen', 'savage', 'beauty']\n",
      "[수치] [18, 12, 73, 84, 112, 22, 78, 112, 105, 83]\n"
     ]
    }
   ],
   "source": [
    "## 문장별 토큰 ==> 수치화 \n",
    "SENT_NUM_LIST =[]\n",
    "for sent_line in sent_token_list:\n",
    "    setnums= [ VOCAB_TO_IDX[word] for word in sent_line]\n",
    "    print('\\n[문장]', sent_line)\n",
    "    print('[수치]', setnums)\n",
    "    SENT_NUM_LIST.append(setnums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 79, 80, 49, 119, 59, 78, 112, 62, 27, 99, 119, 104, 78, 112]\n",
      "[80, 111, 48, 115, 117, 44, 43, 17, 116, 39, 119, 29]\n",
      "[37, 9, 85, 72, 60, 19, 28, 7, 119, 15, 74]\n",
      "[42, 25, 81, 100, 34, 8, 24, 2]\n",
      "[70, 50, 71, 103, 88, 118, 30, 31, 6]\n",
      "[38, 96, 70, 10, 109, 57, 52, 113, 108, 40, 108, 119, 14]\n",
      "[43, 56, 70, 108, 89, 38, 21, 66]\n",
      "[82, 114, 21, 101, 96, 70, 26, 98]\n",
      "[70, 10, 81, 36, 65, 20]\n",
      "[98, 102, 51, 86, 55, 32, 116, 23, 5, 106, 97, 46, 13, 115, 107, 106, 3, 68]\n",
      "[11, 75, 80, 90, 35, 47, 58, 95, 120, 91]\n",
      "[43, 93, 70, 63, 12, 54, 121, 119, 29, 76, 94, 67, 53]\n",
      "[69, 122, 87, 4, 33, 110, 15, 64, 92, 41, 61, 16, 112, 77, 45]\n",
      "[18, 12, 73, 84, 112, 22, 78, 112, 105, 83]\n"
     ]
    }
   ],
   "source": [
    "## 숫자 문장들 체크\n",
    "for _ in SENT_NUM_LIST: print( _ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 패딩 : 모든 문장 길이 맞추기<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장별 단어 개수 :  [15, 12, 11, 8, 9, 13, 8, 8, 6, 18, 10, 13, 15, 10]\n",
      "가장 긴 문장    :  18, 가장 짧은 문장 :6\n"
     ]
    }
   ],
   "source": [
    "## 문자별 단어 갯수 체크\n",
    "length  = [ len(sent) for sent in SENT_NUM_LIST]\n",
    "\n",
    "print(f'문장별 단어 개수 :  {length}')\n",
    "print(f'가장 긴 문장    :  {max(length)}, 가장 짧은 문장 :{min(length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 문장별 길이 일치 => 가장 긴문장\n",
    "MAX_LEN = max(length)\n",
    "NUMS = len(SENT_NUM_LIST)\n",
    "for idx in range(NUMS):\n",
    "    sent_len = len(SENT_NUM_LIST[idx])\n",
    "    if sent_len != MAX_LEN:\n",
    "        for _ in range(MAX_LEN-sent_len):\n",
    "            SENT_NUM_LIST[idx].append( VOCAB_TO_IDX['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18개 : [12, 79, 80, 49, 119, 59, 78, 112, 62, 27, 99, 119, 104, 78, 112, 0, 0, 0]\n",
      "18개 : [80, 111, 48, 115, 117, 44, 43, 17, 116, 39, 119, 29, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [37, 9, 85, 72, 60, 19, 28, 7, 119, 15, 74, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [42, 25, 81, 100, 34, 8, 24, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [70, 50, 71, 103, 88, 118, 30, 31, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [38, 96, 70, 10, 109, 57, 52, 113, 108, 40, 108, 119, 14, 0, 0, 0, 0, 0]\n",
      "18개 : [43, 56, 70, 108, 89, 38, 21, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [82, 114, 21, 101, 96, 70, 26, 98, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [70, 10, 81, 36, 65, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [98, 102, 51, 86, 55, 32, 116, 23, 5, 106, 97, 46, 13, 115, 107, 106, 3, 68]\n",
      "18개 : [11, 75, 80, 90, 35, 47, 58, 95, 120, 91, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18개 : [43, 93, 70, 63, 12, 54, 121, 119, 29, 76, 94, 67, 53, 0, 0, 0, 0, 0]\n",
      "18개 : [69, 122, 87, 4, 33, 110, 15, 64, 92, 41, 61, 16, 112, 77, 45, 0, 0, 0]\n",
      "18개 : [18, 12, 73, 84, 112, 22, 78, 112, 105, 83, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for _ in SENT_NUM_LIST:\n",
    "    print(f'{len(_)}개 : {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 인코딩<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 18)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "dataNP = np.array(SENT_NUM_LIST)\n",
    "dataNP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인코딩\n",
    "ohEncoder = OneHotEncoder(sparse_output=False)\n",
    "SENT_VEC=ohEncoder.fit_transform(dataNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENT_VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
